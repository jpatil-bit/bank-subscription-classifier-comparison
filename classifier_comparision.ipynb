{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset collected is related to 17 marketing campaigns \n",
      " that occurred between May 2008 and November 2010, \n",
      "corresponding to a total of 79,354 contacts.\n",
      "Source: CRISP-DM-BANK.pdf (Moro et al., 2014) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"The dataset collected is related to 17 marketing campaigns \\n \"\n",
    "    \"that occurred between May 2008 and November 2010, \\n\"\n",
    "    \"corresponding to a total of 79,354 contacts.\\n\"\n",
    "    \"Source: CRISP-DM-BANK.pdf (Moro et al., 2014) \\n\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age;\"job\";\"marital\";\"education\";\"default\";\"housing\";\"loan\";\"contact\";\"month\";\"day_of_week\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"emp.var.rate\";\"cons.price.idx\";\"cons.conf.idx\";\"euribor3m\";\"nr.employed\";\"y\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56;\"housemaid\";\"married\";\"basic.4y\";\"no\";\"no\";...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57;\"services\";\"married\";\"high.school\";\"unknown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37;\"services\";\"married\";\"high.school\";\"no\";\"ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40;\"admin.\";\"married\";\"basic.6y\";\"no\";\"no\";\"no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56;\"services\";\"married\";\"high.school\";\"no\";\"no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age;\"job\";\"marital\";\"education\";\"default\";\"housing\";\"loan\";\"contact\";\"month\";\"day_of_week\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"emp.var.rate\";\"cons.price.idx\";\"cons.conf.idx\";\"euribor3m\";\"nr.employed\";\"y\"\n",
       "0  56;\"housemaid\";\"married\";\"basic.4y\";\"no\";\"no\";...                                                                                                                                                                          \n",
       "1  57;\"services\";\"married\";\"high.school\";\"unknown...                                                                                                                                                                          \n",
       "2  37;\"services\";\"married\";\"high.school\";\"no\";\"ye...                                                                                                                                                                          \n",
       "3  40;\"admin.\";\"married\";\"basic.6y\";\"no\";\"no\";\"no...                                                                                                                                                                          \n",
       "4  56;\"services\";\"married\";\"high.school\";\"no\";\"no...                                                                                                                                                                          "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bank_df = pd.read_csv(\"data/bank-additional-full.csv\")\n",
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y']\n",
      "Counts of 'unknown' values in selected categorical columns:\n",
      "\n",
      "job:\n",
      "job\n",
      "admin.           10422\n",
      "blue-collar       9254\n",
      "technician        6743\n",
      "services          3969\n",
      "management        2924\n",
      "retired           1720\n",
      "entrepreneur      1456\n",
      "self-employed     1421\n",
      "housemaid         1060\n",
      "unemployed        1014\n",
      "student            875\n",
      "unknown            330\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "marital:\n",
      "marital\n",
      "married     24928\n",
      "single      11568\n",
      "divorced     4612\n",
      "unknown        80\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "education:\n",
      "education\n",
      "university.degree      12168\n",
      "high.school             9515\n",
      "basic.9y                6045\n",
      "professional.course     5243\n",
      "basic.4y                4176\n",
      "basic.6y                2292\n",
      "unknown                 1731\n",
      "illiterate                18\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "default:\n",
      "default\n",
      "no         32588\n",
      "unknown     8597\n",
      "yes            3\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "housing:\n",
      "housing\n",
      "yes        21576\n",
      "no         18622\n",
      "unknown      990\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "loan:\n",
      "loan\n",
      "no         33950\n",
      "yes         6248\n",
      "unknown      990\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Numeric columns summary:\n",
      "\n",
      "               age      duration      campaign         pdays      previous  \\\n",
      "count  41188.00000  41188.000000  41188.000000  41188.000000  41188.000000   \n",
      "mean      40.02406    258.285010      2.567593    962.475454      0.172963   \n",
      "std       10.42125    259.279249      2.770014    186.910907      0.494901   \n",
      "min       17.00000      0.000000      1.000000      0.000000      0.000000   \n",
      "25%       32.00000    102.000000      1.000000    999.000000      0.000000   \n",
      "50%       38.00000    180.000000      2.000000    999.000000      0.000000   \n",
      "75%       47.00000    319.000000      3.000000    999.000000      0.000000   \n",
      "max       98.00000   4918.000000     56.000000    999.000000      7.000000   \n",
      "\n",
      "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
      "count  41188.000000    41188.000000   41188.000000  41188.000000  41188.000000  \n",
      "mean       0.081886       93.575664     -40.502600      3.621291   5167.035911  \n",
      "std        1.570960        0.578840       4.628198      1.734447     72.251528  \n",
      "min       -3.400000       92.201000     -50.800000      0.634000   4963.600000  \n",
      "25%       -1.800000       93.075000     -42.700000      1.344000   5099.100000  \n",
      "50%        1.100000       93.749000     -41.800000      4.857000   5191.000000  \n",
      "75%        1.400000       93.994000     -36.400000      4.961000   5228.100000  \n",
      "max        1.400000       94.767000     -26.900000      5.045000   5228.100000  \n",
      "\n",
      "Note: 'duration' should be dropped if predicting subscription before the call occurs.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "bank_df = pd.read_csv(\"data/bank-additional-full.csv\", sep=';')  # Added sep=';' as bank data typically uses semicolons\n",
    "print(bank_df.columns.tolist())  # Print column names to verify what's available\n",
    "bank_df.head()\n",
    "\n",
    "# Step 3: Define categorical columns based on actual column names\n",
    "# Adjust these column names to match what was printed above\n",
    "categorical_cols = ['job','marital','education','default','housing','loan',\n",
    "                    'contact','month','day_of_week','poutcome','y']\n",
    "\n",
    "# Step 4: Convert categorical columns to 'category' type\n",
    "for col in categorical_cols:\n",
    "    if col in bank_df.columns:  # Check if column exists before converting\n",
    "        bank_df[col] = bank_df[col].astype('category')\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' not found in the dataset\")\n",
    "\n",
    "# Step 5: Check for 'unknown' values in key categorical features\n",
    "print(\"Counts of 'unknown' values in selected categorical columns:\\n\")\n",
    "for col in ['job','marital','education','default','housing','loan']:\n",
    "    if col in bank_df.columns:  # Check if column exists before accessing\n",
    "        print(f\"{col}:\")\n",
    "        print(bank_df[col].value_counts())\n",
    "        print(\"-\"*40)\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' not found in the dataset\")\n",
    "\n",
    "# Step 6: Quick summary of numeric columns\n",
    "numeric_cols = ['age','duration','campaign','pdays','previous',\n",
    "                'emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']\n",
    "\n",
    "# Filter to only include columns that exist in the dataset\n",
    "valid_numeric_cols = [col for col in numeric_cols if col in bank_df.columns]\n",
    "\n",
    "print(\"\\nNumeric columns summary:\\n\")\n",
    "print(bank_df[valid_numeric_cols].describe())\n",
    "\n",
    "# Step 7: Suggest dropping 'duration' for realistic predictive modeling\n",
    "print(\"\\nNote: 'duration' should be dropped if predicting subscription before the call occurs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Objective:\n",
      "Predict whether a bank client will subscribe to a term deposit (y = yes/no) using the data provided in the sample , age , job , marital status , etc.\n",
      "The goal is to help the bank optimize marketing efforts, reduce costs of unsuccessful calls, and increase subscription success rates.\n"
     ]
    }
   ],
   "source": [
    "print(\"Business Objective:\\n\"\n",
    "      \"Predict whether a bank client will subscribe to a term deposit (y = yes/no) \"\n",
    "      \"using the data provided in the sample , age , job , marital status , etc.\\n\"\n",
    "      \"The goal is to help the bank optimize marketing efforts, reduce costs of unsuccessful calls, \"\n",
    "      \"and increase subscription success rates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (41188, 28)\n",
      "Target shape: (41188,)\n",
      "\n",
      "First 5 rows of encoded features:\n",
      "   age  job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
      "0   56            False             False           True           False   \n",
      "1   57            False             False          False           False   \n",
      "2   37            False             False          False           False   \n",
      "3   40            False             False          False           False   \n",
      "4   56            False             False          False           False   \n",
      "\n",
      "   job_retired  job_self-employed  job_services  job_student  job_technician  \\\n",
      "0        False              False         False        False           False   \n",
      "1        False              False          True        False           False   \n",
      "2        False              False          True        False           False   \n",
      "3        False              False         False        False           False   \n",
      "4        False              False          True        False           False   \n",
      "\n",
      "   ...  education_illiterate  education_professional.course  \\\n",
      "0  ...                 False                          False   \n",
      "1  ...                 False                          False   \n",
      "2  ...                 False                          False   \n",
      "3  ...                 False                          False   \n",
      "4  ...                 False                          False   \n",
      "\n",
      "   education_university.degree  education_unknown  default_unknown  \\\n",
      "0                        False              False            False   \n",
      "1                        False              False             True   \n",
      "2                        False              False            False   \n",
      "3                        False              False            False   \n",
      "4                        False              False            False   \n",
      "\n",
      "   default_yes  housing_unknown  housing_yes  loan_unknown  loan_yes  \n",
      "0        False            False        False         False     False  \n",
      "1        False            False        False         False     False  \n",
      "2        False            False         True         False     False  \n",
      "3        False            False        False         False     False  \n",
      "4        False            False        False         False      True  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select bank client features (first 7)\n",
    "X = bank_df[['age', 'job', 'marital', 'education', 'default', 'housing', 'loan']]\n",
    "\n",
    "# Target variable\n",
    "y = bank_df['y']\n",
    "categorical_cols = ['job','marital','education','default','housing','loan']\n",
    "# One-hot encode categorical columns\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "# Encode target: 'yes' -> 1, 'no' -> 0\n",
    "y_encoded = y.map({'yes': 1, 'no': 0})\n",
    "print(\"Features shape:\", X_encoded.shape)\n",
    "print(\"Target shape:\", y_encoded.shape)\n",
    "print(\"\\nFirst 5 rows of encoded features:\")\n",
    "print(X_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (28831, 28)\n",
      "X_test shape: (12357, 28)\n",
      "y_train shape: (28831,)\n",
      "y_test shape: (12357,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into train and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    ")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "0    36548\n",
      "1     4640\n",
      "Name: count, dtype: int64\n",
      "Baseline accuracy (majority class): 0.8873\n"
     ]
    }
   ],
   "source": [
    "# Count target classes\n",
    "class_counts = y_encoded.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Calculate proportion of majority class\n",
    "baseline_accuracy = class_counts.max() / class_counts.sum()\n",
    "print(f\"Baseline accuracy (majority class): {baseline_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8874\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10965     0]\n",
      " [ 1392     0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     10965\n",
      "           1       0.00      0.00      0.00      1392\n",
      "\n",
      "    accuracy                           0.89     12357\n",
      "   macro avg       0.44      0.50      0.47     12357\n",
      "weighted avg       0.79      0.89      0.83     12357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Initialize Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate test accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.317924</td>\n",
       "      <td>0.887343</td>\n",
       "      <td>0.887351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>3.447798</td>\n",
       "      <td>0.887343</td>\n",
       "      <td>0.887351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.890985</td>\n",
       "      <td>0.875293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.041436</td>\n",
       "      <td>0.918837</td>\n",
       "      <td>0.863883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Time (s)  Train Accuracy  Test Accuracy\n",
       "0  Logistic Regression        0.317924        0.887343       0.887351\n",
       "1                  SVM        3.447798        0.887343       0.887351\n",
       "2                  KNN        0.002605        0.890985       0.875293\n",
       "3        Decision Tree        0.041436        0.918837       0.863883"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define models with default settings\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through models\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)             # Train the model\n",
    "    train_time = time.time() - start_time   # Measure fit time\n",
    "    \n",
    "    # Predict on train and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute accuracies\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train Time (s)\": train_time,\n",
    "        \"Train Accuracy\": train_acc,\n",
    "        \"Test Accuracy\": test_acc\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display results\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y']\n",
      "Detected target column: y\n",
      "\n",
      "Model Comparison Results:\n",
      "                  Model  Train Time (s)  Train Accuracy  Test Accuracy\n",
      "0  Logistic Regression           0.136          0.9108         0.9121\n",
      "1        Decision Tree           0.029          0.9090         0.9098\n",
      "2                  SVM          52.940          0.9546         0.9097\n",
      "3                  KNN           0.009          0.9407         0.9002\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# PROOF: Feature Engineering, Hyperparameter Tuning, and Metrics\n",
    "# Fully robust version\n",
    "# ==============================\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ------------------------------\n",
    "# 1Ô∏è‚É£ Load Dataset\n",
    "# ------------------------------\n",
    "file_path = \"data/bank-additional-full.csv\"\n",
    "bank_df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Inspect columns\n",
    "print(\"Columns in dataset:\", bank_df.columns.tolist())\n",
    "\n",
    "# ------------------------------\n",
    "# 2Ô∏è‚É£ Detect Target Column Automatically\n",
    "# ------------------------------\n",
    "target_col = None\n",
    "for col in bank_df.columns:\n",
    "    if set(bank_df[col].dropna().unique()) == {'yes','no'}:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\"No column with 'yes'/'no' values found in dataset!\")\n",
    "\n",
    "print(\"Detected target column:\", target_col)\n",
    "\n",
    "# ------------------------------\n",
    "# 3Ô∏è‚É£ Feature Engineering\n",
    "# ------------------------------\n",
    "# Create total_loans if possible\n",
    "loan_cols = ['housing','loan','default']\n",
    "existing_loan_cols = [col for col in loan_cols if col in bank_df.columns]\n",
    "\n",
    "if existing_loan_cols:\n",
    "    bank_df['total_loans'] = bank_df[existing_loan_cols].apply(\n",
    "        lambda x: sum([1 if v=='yes' else 0 for v in x]), axis=1\n",
    "    )\n",
    "else:\n",
    "    bank_df['total_loans'] = 0\n",
    "\n",
    "# ------------------------------\n",
    "# 4Ô∏è‚É£ Detect Numeric and Categorical Columns Automatically\n",
    "# ------------------------------\n",
    "numeric_cols = bank_df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "# Include total_loans if it exists\n",
    "if 'total_loans' in bank_df.columns and 'total_loans' not in numeric_cols:\n",
    "    numeric_cols.append('total_loans')\n",
    "\n",
    "# Exclude target if numeric\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "\n",
    "categorical_cols = bank_df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Exclude target from categorical\n",
    "if target_col in categorical_cols:\n",
    "    categorical_cols.remove(target_col)\n",
    "\n",
    "# ------------------------------\n",
    "# 5Ô∏è‚É£ One-hot Encoding\n",
    "# ------------------------------\n",
    "X = pd.get_dummies(bank_df[categorical_cols + numeric_cols], drop_first=True)\n",
    "\n",
    "# Map target to 0/1\n",
    "y = bank_df[target_col].map({'yes':1,'no':0})\n",
    "\n",
    "# ------------------------------\n",
    "# 6Ô∏è‚É£ Train-Test Split\n",
    "# ------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize numeric features for KNN/SVM\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "\n",
    "# Check the target variable format and convert if necessary\n",
    "# If y contains 'yes'/'no' values, convert them to 1/0\n",
    "if isinstance(y_train.iloc[0], str):\n",
    "    # Convert 'yes'/'no' or other string labels to 0/1\n",
    "    y_train = y_train.map({'yes': 1, 'no': 0}) if 'yes' in y_train.unique() else y_train\n",
    "    y_test = y_test.map({'yes': 1, 'no': 0}) if 'yes' in y_test.unique() else y_test\n",
    "    \n",
    "# ------------------------------\n",
    "# 7Ô∏è‚É£ Hyperparameter Tuning\n",
    "# ------------------------------\n",
    "# Decision Tree\n",
    "dt_param_grid = {'max_depth':[3,5,7,10,None],\n",
    "                 'min_samples_split':[2,5,10],\n",
    "                 'min_samples_leaf':[1,2,4]}\n",
    "grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "# KNN\n",
    "knn_param_grid = {'n_neighbors':[3,5,7,9], 'weights':['uniform','distance']}\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_param_grid = {'C':[0.01,0.1,1,10], 'penalty':['l2']}\n",
    "grid_lr = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), lr_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "# SVM\n",
    "svm_param_grid = {'C':[0.1,1,10], 'kernel':['linear','rbf'], 'gamma':['scale','auto']}\n",
    "grid_svm = GridSearchCV(SVC(random_state=42, probability=True), svm_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------------\n",
    "# 8Ô∏è‚É£ Evaluate Metrics\n",
    "# ------------------------------\n",
    "models = {\n",
    "    'Decision Tree': grid_dt.best_estimator_,\n",
    "    'KNN': grid_knn.best_estimator_,\n",
    "    'Logistic Regression': grid_lr.best_estimator_,\n",
    "    'SVM': grid_svm.best_estimator_\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Time (s)': round(train_time,3),\n",
    "        'Train Accuracy': round(accuracy_score(y_train, y_train_pred),4),\n",
    "        'Test Accuracy': round(accuracy_score(y_test, y_test_pred),4)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='Test Accuracy', ascending=False)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"\\nModel Comparison Results:\\n\", results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Model trained successfully\n",
      "\n",
      "Number of likely subscribers (prob ‚â• 0.7): 503\n",
      "\n",
      "Sample likely subscribers:\n",
      "       age            job  marital          education default housing loan  \\\n",
      "39993   27        unknown   single  university.degree      no     yes   no   \n",
      "40731   19        student   single           basic.4y      no     yes   no   \n",
      "22705   32         admin.  married  university.degree      no     yes   no   \n",
      "13137   35  self-employed   single  university.degree      no     yes   no   \n",
      "30359   36         admin.  married  university.degree      no     yes   no   \n",
      "\n",
      "        contact month day_of_week  ...  campaign  pdays  previous  \\\n",
      "39993  cellular   jun         wed  ...         4      3         2   \n",
      "40731  cellular   sep         wed  ...         2      6         3   \n",
      "22705  cellular   aug         fri  ...         1    999         0   \n",
      "13137  cellular   jul         wed  ...         1    999         0   \n",
      "30359  cellular   apr         thu  ...         1    999         1   \n",
      "\n",
      "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "39993      success         -1.7          94.055          -39.8      0.767   \n",
      "40731      success         -1.1          94.199          -37.5      0.876   \n",
      "22705  nonexistent          1.4          93.444          -36.1      4.964   \n",
      "13137  nonexistent          1.4          93.918          -42.7      4.962   \n",
      "30359      failure         -1.8          93.075          -47.1      1.365   \n",
      "\n",
      "       nr.employed    y  \n",
      "39993       4991.6  yes  \n",
      "40731       4963.6  yes  \n",
      "22705       5228.1   no  \n",
      "13137       5228.1  yes  \n",
      "30359       5099.1  yes  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "File saved as likely_subscribers.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Predict Customers Likely to Subscribe\n",
    "# UCI Bank Marketing Dataset\n",
    "# ==============================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ------------------------------\n",
    "# 1Ô∏è‚É£ Load dataset (IMPORTANT: semicolon separator)\n",
    "# ------------------------------\n",
    "file_path = \"data/bank-additional-full.csv\"\n",
    "\n",
    "bank_df = pd.read_csv(file_path, sep=\";\")\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(bank_df.head())\n",
    "\n",
    "# ------------------------------\n",
    "# 2Ô∏è‚É£ Separate features and target\n",
    "# ------------------------------\n",
    "X = bank_df.drop(columns=[\"y\"])\n",
    "y = bank_df[\"y\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# ------------------------------\n",
    "# 3Ô∏è‚É£ One-hot encode categorical features\n",
    "# ------------------------------\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 4Ô∏è‚É£ Train-test split\n",
    "# ------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 5Ô∏è‚É£ Scale features\n",
    "# ------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------\n",
    "# 6Ô∏è‚É£ Train Logistic Regression model\n",
    "# ------------------------------\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained successfully\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7Ô∏è‚É£ Predict subscription probabilities\n",
    "# ------------------------------\n",
    "subscription_probabilities = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# ------------------------------\n",
    "# 8Ô∏è‚É£ Select likely subscribers (threshold = 70%)\n",
    "# ------------------------------\n",
    "threshold = 0.70\n",
    "likely_subscribers_idx = X_test.index[subscription_probabilities >= threshold]\n",
    "\n",
    "likely_subscribers = bank_df.loc[likely_subscribers_idx]\n",
    "\n",
    "print(f\"\\nNumber of likely subscribers (prob ‚â• {threshold}):\", len(likely_subscribers))\n",
    "\n",
    "# ------------------------------\n",
    "# 9Ô∏è‚É£ View sample likely subscribers\n",
    "# ------------------------------\n",
    "print(\"\\nSample likely subscribers:\")\n",
    "print(likely_subscribers.head())\n",
    "\n",
    "# ------------------------------\n",
    "# üîü (Optional) Save results\n",
    "# ------------------------------\n",
    "likely_subscribers.to_csv(\"likely_subscribers.csv\", index=False)\n",
    "print(\"\\nFile saved as likely_subscribers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
